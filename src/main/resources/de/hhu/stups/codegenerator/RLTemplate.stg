trace_generator(name, modelPath, learningTechnique, episodes, hasSetupConstants, actionMapping, variableMapping, variablePredicate, getters, transitions, invariant, generateTraces) ::= <<
import gymnasium as gym
import json
import copy
from stable_baselines3 import <learningTechnique>
import warnings
warnings.filterwarnings("ignore")

<if(generateTraces)>

def write_trace(transitionList, i):
    trace = {
        "description": "",
        "transitionList": transitionList
    }
    jsonString = json.dumps(trace, indent=4)
    f = open("Trace_{0}.prob2trace".format(i), "w")
    f.write(jsonString)
    f.close()


def write_timed_trace(transitionList, i):
    trace = {
        "activations": transitionList
    }
    jsonString = json.dumps(trace, indent=4)
    f = open("Timed_Trace_{0}.prob2trace".format(i), "w")
    f.write(jsonString)
    f.close()

episodes = <episodes>

i = 0

<endif>

env = gym.make('<name>')
env.reset()

# Load pre-trained model
model = <learningTechnique>.load("<modelPath>")


# TODO: Implement mapping of action id to action name
action_names = {
    <actionMapping; separator=", \t\n">
}

action_names_inv = {val: key for key, val in action_names.items()}

<getters; separator="\n\n">

<if(generateTraces)>

def append_transition(obs, transition_list, operation):
    transition_list.append({
        "name": operation,
        "destState": {} if "$setup_constants" == operation else {
            <variableMapping; separator="\n">
        }
    })


def append_timed_transition(is_initialisation, done, index, obs, transition_list, operation, delta):
    transition_list.append({
        "id": operation if is_initialisation else "activation_" + str(index),
        "execute": operation,
        "after": delta if not is_initialisation else 0,
        "activating": "activation_" + str(index + 1) if not done else [],
        "fixedVariables": {} if "$setup_constants" == operation else {
            <variableMapping; separator="\n">
        }
    })

<endif>

<if(generateTraces)>
for ep in range(episodes):
    i = i + 1
    obs = env.reset()
    done = False
    transition_list = []
    timed_transition_list = []
    j = 0
    delta = 1000
    while not done:
        j = j + 1
        action, _states = model.predict(obs)
        obs, rewards, done, info = env.step(int(action))
        env.render()
        actionName = action_names.get(int(action))

        <if(hasSetupConstants)>
        if j == 1:
           append_transition(obs, transition_list, "$setup_constants")
           append_timed_transition(True, done, j, obs, timed_transition_list, "$setup_constants", delta)
        elif j == 2:
           append_transition(obs, transition_list, "$initialise_machine")
           append_timed_transition(True, done, j, obs, timed_transition_list, "$initialise_machine", delta)
        else:
           append_transition(obs, transition_list, actionName)
           append_timed_transition(False, done, j, obs, timed_transition_list, actionName, delta)
        <else>
        if j == 1:
           append_transition(obs, transition_list, "$initialise_machine")
           append_timed_transition(True, done, j, obs, timed_transition_list, "$initialise_machine", delta)
        else:
           append_transition(obs, transition_list, actionName)
           append_timed_transition(False, done, j, obs, timed_transition_list, actionName, delta)
        <endif>
        write_trace(transition_list, i)
        write_timed_trace(timed_transition_list, i)
<else>
while True:
    obs = env.reset()[0]
    rewards = 0.0
    info = None
    done = False
    finished = False
    delta = 1000

    finished = (int(input("")) == 1)
    input("")
    print("$initialise_machine")
    print(0)
    print(<variablePredicate; separator=" + \" & \" + ">)
    print("false")

    while not done and not finished:
        finished = int(input("")) == 1
        if finished:
            break



        enabled_operations = input("")
        operations_list = enabled_operations.split(",")

        obs_tensor, _ = model.policy.obs_to_tensor(obs)
        predictions = model.policy.q_net(obs_tensor)
        action_order = (-predictions).argsort(dim=1)

        new_action = action

        for action in action_order[0]:
            if action_names.get(int(action)) in operations_list:
                new_action = action
                break

        obs, rewards, done, truncated, info = env.step(int(new_action))
        actionName = action_names.get(int(new_action))

        print(actionName)
        print(delta)
        print(<variablePredicate; separator=" + \" & \" + ">)
        print("true" if done else "false")

<endif>

env.close()
>>


state(variables) ::= <<
<variables; separator=",\n">
>>

variable_map(variable) ::= <<
"<variable>": get_<variable>(obs)
>>

variable_pred(variable) ::= <<
"<variable> = {0}".format(get_<variable>(obs))
>>

variable_getter(variable) ::= <<
def get_<variable>(obs):
    # TODO: Implement mapping of state to variable
>>

action_map(id) ::= <<
<id>: ""
>>